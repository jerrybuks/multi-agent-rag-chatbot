# Multi-Agent RAG Chatbot

A multi-agent RAG (Retrieval Augmented Generation) chatbot system for JupiterIQ that handles customer inquiries across multiple departments (HR, Tech, Finance, Legal).

## Live Demo & Monitoring

<!-- - **Product Demo**: [https://rag-chatbot-fe-self.vercel.app/](https://rag-chatbot-fe-self.vercel.app) -->

- **API Documentation**: [https://multi-agent-rag-chatbot.onrender.com/docs](https://multi-agent-rag-chatbot.onrender.com/docs)
- **Status Page**: [https://stats.uptimerobot.com/5z2EBCHShQ](https://stats.uptimerobot.com/5z2EBCHShQ)
<!-- - **Metrics**: [https://rag-based-chatbot-96uz.onrender.com/api/v1/query/metrics](https://rag-based-chatbot-96uz.onrender.com/api/v1/query/metrics) -->
- **Report**: [https://github.com/jerrybuks/multi-agent-rag-chatbot/blob/main/reports/REPORT.md](https://github.com/jerrybuks/multi-agent-rag-chatbot/blob/main/reports/REPORT.md)


## Documentation

- **[ðŸ“Š Technical Report](reports/REPORT.md)** - Comprehensive architecture, design decisions, and system overview
- **[ðŸ”„ Flow Diagrams](FLOW_DIAGRAM.md)** - Component interaction diagram and key decision points
- **[ðŸ“š Golden Datasets](data/golden_datasets/README.md)** - Test dataset documentation

## API Key Setup

1. You can run this app with either openAI key or [OpenRouter](https://openrouter.ai/) key
   - Sign up for an account at OpenRouter or OpenAI
   - Navigate to API Keys section
   - Create a new API key

   You will also need to setup [langfuse](https://cloud.langfuse.com/)
   - sign up on langfuse
   - creat a project and get your keys (secret and private key)


2. Add your API keys to the `.env` file:
   ```bash
   OPENAI_API_KEY=your_api_key_here
   LANGFUSE_PUBLIC_KEY=langfuse_public_key
   LANGFUSE_SECRET_KEY=langfuse_secret_key
   ```
   if you are using OpenRouter you will also need to add a Base url in your env
    ```bash
   OPENAI_API_BASE=https://openrouter.ai/api/v1
   ```

## Starting Local Server Setup

### 1. Create Virtual Environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install .
```

### 3. Build the Vector Index

Run the indexing script to process handbooks and generate embeddings:

```bash
python src/build_index.py
```

This will:
- Load all handbook markdown files from the `data/` folder
- Intelligently chunk each handbook using markdown header-based splitting
- Generate embeddings for each chunk
- Save chunks and embeddings to JSONL files in the `data/` folder

### Output Files

The script generates the following files in the `data/` folder:

- `{handbook_name}_chunks.jsonl` - Chunks without embeddings (one per handbook)
- `{handbook_name}_embeddings.jsonl` - Chunks with embeddings (one per handbook)
- `all_handbooks_chunks.jsonl` - Combined chunks from all handbooks
- `all_handbooks_embeddings.jsonl` - Combined chunks with embeddings

## Running the Application

```bash
fastapi dev src/main.py
```

The server will be available at `http://localhost:8000`

- **API Docs**: http://localhost:8000/docs

## Running Tests

The system includes a test runner that uses golden datasets to validate the chatbot's responses with automatic quality scoring via Langfuse.

### Quick Start

Run all tests:
```bash
python tests/test_runner.py
```

Run a specific dataset:
```bash
python tests/test_runner.py --dataset finance.jsonl
```

Run with custom settings:
```bash
python tests/test_runner.py \
  --dataset finance.jsonl \
  --max-tests 5 \
  --min-similarity 0.75
```

## Project Structure

```
.
â”œâ”€â”€ data/                    # Handbook markdown files and generated indexes
â”‚   â”œâ”€â”€ handbooks/          # Source handbook markdown files
â”‚   â”œâ”€â”€ jsonl/              # Generated chunks (JSONL format)
â”‚   â”œâ”€â”€ vectorstore/        # Chroma vector stores (one per handbook)
â”‚   â””â”€â”€ golden_datasets/    # Test datasets for evaluation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ build_index.py      # Index building script
â”‚   â”œâ”€â”€ main.py             # FastAPI application
â”‚   â”œâ”€â”€ indexing/           # Indexing utilities (parsing, chunking, embeddings)
â”‚   â”œâ”€â”€ querying/           # Query processing (agents, routes, tools)
â”‚   â”œâ”€â”€ evaluation/         # Langfuse evaluator for quality scoring
â”‚   â”œâ”€â”€ config/             # Configuration settings
â”‚   â””â”€â”€ utils/              # Utility functions (LLM, storage)
â”œâ”€â”€ tests/                  # Test files
â”‚   â””â”€â”€ test_runner.py      # Golden dataset test runner
â”œâ”€â”€ reports/                # Documentation and reports
â”‚   â””â”€â”€ REPORT.md           # Comprehensive technical report
â””â”€â”€ pyproject.toml          # Python dependencies
```

## Known Limitations

1. **Session Management**: Session IDs are generated from IP addresses, which means users behind the same NAT/proxy will share session context.
2. **Context Window**: Conversation history is limited to the last 20 messages to prevent context bloat and maintain performance.
3. **Vector Store**: Vector stores are preloaded at startup and stored in memory; very large knowledge bases may require additional memory resources.

